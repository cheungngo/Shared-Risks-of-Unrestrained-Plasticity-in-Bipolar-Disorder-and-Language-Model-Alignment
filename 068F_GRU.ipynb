{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"A100","authorship_tag":"ABX9TyOkGxrNAm9BaUbbKPDgV50n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# GRU Upgrade"],"metadata":{"id":"38OWLf_cC17-"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5DU2qrT4C00h","executionInfo":{"status":"ok","timestamp":1768927052932,"user_tz":-480,"elapsed":30487247,"user":{"displayName":"Ngo Cheung","userId":"02091267041339546959"}},"outputId":"7769b157-775c-4169-9bd9-74b2a641133d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","################################################################################\n","#                                                                              #\n","#                  MULTI-MECHANISM ANTIDEPRESSANT COMPARISON                   #\n","#           WITH MANIC CONVERSION + LONGITUDINAL RELAPSE + KINDLING            #\n","#                       GRU-BASED RECURRENT ARCHITECTURE                       #\n","#                       Ketamine vs SSRI vs Neurosteroid                       #\n","#                              (10 Random Seeds)                               #\n","#                                                                              #\n","################################################################################\n","\n","================================================================================\n","  MULTI-MECHANISM ANTIDEPRESSANT COMPARISON EXPERIMENT\n","  WITH MANIC CONVERSION + LONGITUDINAL RELAPSE + KINDLING\n","  GRU-BASED RECURRENT ARCHITECTURE\n","  Running across 10 random seeds\n","================================================================================\n","\n","  Architecture: GRUCell-based recurrent network\n","  Sequence length (depth analogue): 20\n","  GRU hidden size: 384\n","  Estimated total parameters: ~448,516\n","\n","  Seed 1/10... done\n","\n","  Seed 2/10... done\n","\n","  Seed 3/10... done\n","\n","  Seed 4/10... done\n","\n","  Seed 5/10... done\n","\n","  Seed 6/10... done\n","\n","  Seed 7/10... done\n","\n","  Seed 8/10... done\n","\n","  Seed 9/10... done\n","\n","  Seed 10/10... done\n","\n","================================================================================\n","  AGGREGATED RESULTS ACROSS 10 SEEDS\n","================================================================================\n","\n","--------------------------------------------------------------------------------\n","  TABLE 1: EARLY ADVERSITY (Uniform Random Scarring)\n","--------------------------------------------------------------------------------\n","\n","  Initial scar fraction: 3.00% ± 1.92% (range: 0.06% - 5.80%)\n","\n","--------------------------------------------------------------------------------\n","  TABLE 2: ANTIDEPRESSANT EFFICACY (Mean ± Std)\n","--------------------------------------------------------------------------------\n","\n","  Treatment                  Sparsity     Scar %          Clean       Combined\n","  --------------------------------------------------------------------------\n","  Untreated (pruned)      95.1± 0.1%  3.0±1.9%   42.3±11.2%   42.4±12.9%\n","  Ketamine-like           49.1± 1.0%  3.0±1.9%  100.0± 0.0%   99.8± 0.0%\n","  SSRI-like               95.1± 0.1%  3.0±1.9%   79.4±19.4%   80.3±17.1%\n","  Neurosteroid-like       95.1± 0.1%  3.0±1.9%  100.0± 0.0%   99.8± 0.2%\n","\n","--------------------------------------------------------------------------------\n","  TABLE 3: MANIC CONVERSION RISK METRICS (Mean ± Std)\n","--------------------------------------------------------------------------------\n","\n","  Treatment                    Gain      Biased Stress     Act. Magnitude\n","  ----------------------------------------------------------------------\n","  Untreated (pruned)      1.00±0.00         25.3± 0.5%        0.067±0.020\n","  Ketamine-like           1.25±0.00         26.6± 1.2%        0.254±0.015\n","  SSRI-like               1.60±0.00         25.3± 0.4%        0.136±0.028\n","  Neurosteroid-like       0.85±0.00         26.0± 1.4%        0.294±0.052\n","\n","--------------------------------------------------------------------------------\n","  TABLE 4: ACUTE RELAPSE VULNERABILITY (Mean ± Std)\n","--------------------------------------------------------------------------------\n","\n","  Treatment                    Relapse Drop\n","  ------------------------------------------\n","  Ketamine-like            -0.0± 0.1%\n","  SSRI-like                 1.9± 8.7%\n","  Neurosteroid-like         1.3± 2.0%\n","\n","================================================================================\n","  LONGITUDINAL MANIC RELAPSE AFTER DISCONTINUATION\n","================================================================================\n","\n","  Protocol: MS + antidepressant maintenance, then all medications discontinued.\n","            Manic relapse threshold: biased stress accuracy < 60%\n","\n","--------------------------------------------------------------------------------\n","  TABLE 5: OVERALL MANIC RELAPSE PROBABILITY\n","--------------------------------------------------------------------------------\n","\n","  Treatment                    Mean        Std        Min        Max\n","  ----------------------------------------------------------------\n","  Ketamine-like              100.0%       0.0%     100.0%     100.0%\n","  SSRI-like                  100.0%       0.0%     100.0%     100.0%\n","  Neurosteroid-like          100.0%       0.0%     100.0%     100.0%\n","\n","--------------------------------------------------------------------------------\n","  TABLE 6: MANIC RELAPSE RATE BY MAINTENANCE DURATION\n","--------------------------------------------------------------------------------\n","\n","  Treatment                25       50      100      150      200      300 epochs\n","  ------------------------------------------------------------------------\n","  Ketamine-like          100%     100%     100%     100%     100%     100%\n","  SSRI-like              100%     100%     100%     100%     100%     100%\n","  Neurosteroid-like      100%     100%     100%     100%     100%     100%\n","\n","================================================================================\n","  KINDLING: PROGRESSIVE SENSITIZATION VIA REPEATED EPISODES\n","================================================================================\n","\n","  Architecture mechanism: Uniform base scarring upon each manic relapse.\n","  Severity factor computed from current gain and activation magnitude (emergent).\n","  Trigger bias weakens over cycles to test spontaneous episode emergence.\n","  Base scar sparsity: 5.0%\n","  Autonomy threshold: biased stress accuracy < 70% at weak trigger\n","\n","--------------------------------------------------------------------------------\n","  TABLE 7: KINDLING SUMMARY (Mean ± Std)\n","--------------------------------------------------------------------------------\n","\n","  Treatment            Total Relapses   Final Scar %  Autonomy Rate   Autonomy Acc\n","  ------------------------------------------------------------------------------\n","  Ketamine-like          6.0±  0.0   32.7± 1.4%           100%   26.0± 1.3%\n","  SSRI-like              6.0±  0.0    5.0± 1.9%           100%   25.3± 0.7%\n","  Neurosteroid-like      6.0±  0.0    4.6± 1.9%            90%   50.5±10.9%\n","\n","--------------------------------------------------------------------------------\n","  TABLE 8: KINDLING PROGRESSION BY CYCLE\n","--------------------------------------------------------------------------------\n","\n","  Ketamine-like:\n","   Cycle  Trigger     Biased Acc    Relapse %         Scar %   Severity\n","  ------------------------------------------------------------------\n","       0     1.50   26.5± 1.3%         100%    7.0± 1.8%      1.56\n","       1     1.30   26.7± 1.6%         100%   11.8± 1.8%      1.57\n","       2     1.10   26.4± 1.9%         100%   17.0± 1.7%      1.58\n","       3     0.90   26.0± 1.3%         100%   22.3± 1.6%      1.59\n","       4     0.70   25.4± 0.9%         100%   27.6± 1.5%      1.59\n","       5     0.50   25.9± 1.3%         100%   32.7± 1.4%      1.59\n","\n","  SSRI-like:\n","   Cycle  Trigger     Biased Acc    Relapse %         Scar %   Severity\n","  ------------------------------------------------------------------\n","       0     1.50   25.4± 0.4%         100%    3.4± 1.9%      1.67\n","       1     1.30   25.4± 0.6%         100%    3.8± 1.9%      1.69\n","       2     1.10   25.7± 0.5%         100%    4.1± 1.9%      1.71\n","       3     0.90   25.6± 0.5%         100%    4.4± 1.9%      1.72\n","       4     0.70   25.3± 0.7%         100%    4.7± 1.9%      1.74\n","       5     0.50   25.3± 1.0%         100%    5.0± 1.9%      1.76\n","\n","  Neurosteroid-like:\n","   Cycle  Trigger     Biased Acc    Relapse %         Scar %   Severity\n","  ------------------------------------------------------------------\n","       0     1.50   25.4± 1.1%         100%    3.3± 1.9%      1.24\n","       1     1.30   25.8± 1.2%         100%    3.6± 1.9%      1.32\n","       2     1.10   26.0± 1.7%         100%    3.9± 1.9%      1.34\n","       3     0.90   26.8± 1.9%         100%    4.1± 1.9%      1.34\n","       4     0.70   28.6± 4.3%         100%    4.4± 1.9%      1.35\n","       5     0.50   35.5± 8.9%         100%    4.6± 1.9%      1.35\n","\n","--------------------------------------------------------------------------------\n","  TABLE 9: KINDLING ARCHITECTURE PARAMETERS\n","--------------------------------------------------------------------------------\n","\n","  Parameter                                          Value\n","  ---------------------------------------------------------\n","  Base scar sparsity per episode                      5.0%\n","  Severity factor range                       0.5 - 2.0\n","  Number of cycles                                       6\n","  Initial trigger bias                                1.50\n","  Final trigger bias                                  0.50\n","  Autonomy test bias                                  0.30\n","\n","--------------------------------------------------------------------------------\n","  TABLE 10: NEUROSTEROID MEDICATION DEPENDENCE (Mean ± Std)\n","--------------------------------------------------------------------------------\n","\n","  Condition                                Combined            Extreme             Biased\n","  --------------------------------------------------------------------------------------\n","  On medication                    99.8± 0.2%   97.4± 1.7%   26.0± 1.4%\n","  Off medication                   64.9±22.7%   60.4±21.4%   25.4± 0.5%\n","\n","================================================================================\n","  SUMMARY COMPARISON MATRIX\n","================================================================================\n","\n","  ┌─────────────────────┬────────────┬────────────┬──────────────┬─────────────┐\n","  │ Metric              │ Ketamine   │ SSRI       │ Neurosteroid │ Untreated   │\n","  ├─────────────────────┼────────────┼────────────┼──────────────┼─────────────┤\n","  │ Combined Stress (%) │       99.8 │       80.3 │         99.8 │        42.4 │\n","  │ Biased Stress (%)   │       26.6 │       25.3 │         26.0 │        25.3 │\n","  │ Gain Multiplier     │       1.25 │       1.60 │         0.85 │        1.00 │\n","  │ Acute Relapse Drop  │       -0.0 │        1.9 │          1.3 │         N/A │\n","  │ Long. Relapse Prob. │     100.0% │     100.0% │       100.0% │         N/A │\n","  │ Kindling Relapses   │        6.0 │        6.0 │          6.0 │         N/A │\n","  │ Final Scar (%)      │       32.7 │        5.0 │          4.6 │         N/A │\n","  │ Autonomy Rate (%)   │        100 │        100 │           90 │         N/A │\n","  └─────────────────────┴────────────┴────────────┴──────────────┴─────────────┘\n","\n","--------------------------------------------------------------------------------\n","  KINDLING RISK RANKING (by autonomy rate and total relapses)\n","--------------------------------------------------------------------------------\n","\n","  Rank   Treatment                Autonomy %     Relapses   Final Scar %\n","  --------------------------------------------------------------------\n","  1      Neurosteroid-like               90%          6.0           4.6%\n","  2      Ketamine-like                  100%          6.0          32.7%\n","  3      SSRI-like                      100%          6.0           5.0%\n","\n","  Note: Lower autonomy rate and fewer relapses = better kindling resistance\n","        Scar accumulation reflects permanent structural damage from episodes\n","\n","================================================================================\n","  EXPERIMENT COMPLETE\n","  GRU-based recurrent architecture with per-step modulations\n","  Results averaged across 10 random seeds\n","================================================================================\n","\n"]}],"source":["\"\"\"\n","================================================================================\n","MULTI-MECHANISM ANTIDEPRESSANT COMPARISON EXPERIMENT\n","WITH MANIC CONVERSION RISK MODELING + LONGITUDINAL MANIC RELAPSE + KINDLING\n","================================================================================\n","\n","GRU-BASED RECURRENT ARCHITECTURE UPGRADE:\n","- Replaced feed-forward MLP with GRUCell-based recurrent network\n","- Per-layer modulations become per-time-step modulations\n","- Hidden state carries memory across steps (better instability modeling)\n","- Positive bias compounds over recurrent steps (more realistic mania)\n","- All other logic (pruning, scarring, treatments, kindling) unchanged\n","\n","This script compares three antidepressant mechanisms and models:\n","1. Acute treatment efficacy\n","2. Manic conversion risk (treatment-emergent mania)\n","3. Longitudinal manic relapse after medication discontinuation\n","4. Kindling hypothesis: progressive sensitization via uniform irreversible scarring\n","\n","Key Architecture/Parameter Changes for Kindling:\n","- Added scar_masks to PruningManager: Tracks permanently damaged connections\n","- Uniform base scarring (0.05) applied upon each manic relapse\n","- Emergent severity scaling based on current gain and activation magnitude\n","- Gradient-guided regrowth respects scar_masks (cannot regrow scarred positions)\n","- Multi-cycle simulation with weakening triggers to test autonomy emergence\n","- Early adversity modeling via random initial permanent pruning\n","\n","Treatment differentiation emerges from existing architecture:\n","- Ketamine: Regrowth compensates for scars, moderate gain\n","- SSRI: High gain amplifies vulnerability, no structural repair\n","- Neurosteroid: Low gain/inhibition buffers acute damage\n","================================================================================\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader, TensorDataset\n","from typing import Dict, Tuple, List\n","import warnings\n","from collections import defaultdict\n","import copy\n","\n","warnings.filterwarnings('ignore', category=UserWarning)\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# ============================================================================\n","# CONFIGURATION\n","# ============================================================================\n","CONFIG = {\n","    'n_seeds': 10,\n","    'n_train': 12000,\n","    'n_test': 4000,\n","    'n_clean_test': 2000,\n","    'data_noise': 0.8,\n","    'batch_size': 128,\n","    'hidden_dims': [512, 512, 256],  # Kept for reference/compatibility\n","    'input_dim': 2,\n","    'output_dim': 4,\n","    'baseline_epochs': 20,\n","    'baseline_lr': 0.001,\n","    'finetune_epochs': 15,\n","    'finetune_lr': 0.0005,\n","    'prune_sparsity': 0.95,\n","    'regrow_fraction': 0.5,\n","    'regrow_init_scale': 0.03,\n","    'gradient_accumulation_batches': 30,\n","    'extended_stress_levels': {\n","        'none': 0.0,\n","        'moderate': 0.5,\n","        'high': 1.0,\n","        'severe': 1.5,\n","        'extreme': 2.5\n","    },\n","    'monoaminergic_epochs': 100,\n","    'monoaminergic_lr': 1e-5,\n","    'monoaminergic_initial_stress': 0.5,\n","    'ssri_max_gain': 1.6,\n","    'ketamine_gain': 1.25,\n","    'neurosteroid_inhibition_strength': 0.7,\n","    'neurosteroid_use_tanh': True,\n","    'neurosteroid_consolidation_epochs': 10,\n","    'neurosteroid_gain': 0.85,\n","    'mania_test_bias': 1.0,\n","    'mania_test_sigma': 1.0,\n","    'comparison_ketamine_regrow': 0.5,\n","    'comparison_ketamine_epochs': 15,\n","    'comparison_ssri_epochs': 100,\n","    'comparison_neurosteroid_strength': 0.7,\n","    'comparison_neurosteroid_epochs': 10,\n","\n","    # Mood Stabilizer (MS) Architecture Parameters\n","    'ms_gain_cap': 1.05,\n","    'ms_inhib_bias_strength': 0.15,\n","    'ms_bias_damping_factor': 0.3,\n","    'ms_max_protection': 1.0,\n","\n","    # Longitudinal Manic Relapse Parameters\n","    'maintenance_durations': [25, 50, 100, 150, 200, 300],\n","    'maintenance_lr': 1e-6,\n","    'post_discontinuation_steps': 50,\n","    'manic_relapse_threshold': 60.0,\n","\n","    # Treatment-specific MS decay rates (architecture parameter differences)\n","    'ketamine_ms_decay_rate': 0.002,\n","    'ssri_ms_decay_rate': 0.015,\n","    'neurosteroid_ms_decay_rate': 0.008,\n","\n","    # Kindling Parameters (Architecture-based)\n","    'kindling_base_scar_sparsity': 0.05,\n","    'kindling_severity_min': 0.5,\n","    'kindling_severity_max': 2.0,\n","    'kindling_num_cycles': 6,\n","    'kindling_initial_trigger_bias': 1.5,\n","    'kindling_final_trigger_bias': 0.5,\n","    'kindling_inter_episode_maintenance_epochs': 20,\n","    'kindling_autonomy_threshold': 70.0,\n","    'early_adversity_max_scar': 0.06,\n","\n","    # GRU-specific parameters (NEW)\n","    'seq_len': 20,           # Acts as \"depth\" (original had ~3 hidden layers + mods)\n","    'gru_hidden_size': 384,  # Balanced size (original total params ~ similar)\n","}\n","\n","\n","# ============================================================================\n","# DATA GENERATION\n","# ============================================================================\n","def generate_blobs(n_samples: int = 10000, noise: float = 0.8, seed: int = None) -> Tuple[torch.Tensor, torch.Tensor]:\n","    if seed is not None:\n","        rng = np.random.RandomState(seed)\n","    else:\n","        rng = np.random.RandomState()\n","    centers = np.array([[-3, -3], [3, 3], [-3, 3], [3, -3]])\n","    labels = rng.randint(0, 4, n_samples)\n","    data = centers[labels] + rng.randn(n_samples, 2) * noise\n","    return (torch.tensor(data, dtype=torch.float32), torch.tensor(labels, dtype=torch.long))\n","\n","\n","def create_data_loaders(seed: int) -> Tuple[DataLoader, DataLoader, DataLoader]:\n","    seq_len = CONFIG['seq_len']\n","\n","    train_data, train_labels = generate_blobs(CONFIG['n_train'], noise=CONFIG['data_noise'], seed=seed*1000+100)\n","    test_data, test_labels = generate_blobs(CONFIG['n_test'], noise=CONFIG['data_noise'], seed=seed*1000+200)\n","    clean_test_data, clean_test_labels = generate_blobs(CONFIG['n_clean_test'], noise=0.0, seed=seed*1000+300)\n","\n","    # Repeat static input over sequence dimension [N, 2] -> [N, seq_len, 2]\n","    train_data = train_data.unsqueeze(1).repeat(1, seq_len, 1)\n","    test_data = test_data.unsqueeze(1).repeat(1, seq_len, 1)\n","    clean_test_data = clean_test_data.unsqueeze(1).repeat(1, seq_len, 1)\n","\n","    train_loader = DataLoader(TensorDataset(train_data, train_labels), batch_size=CONFIG['batch_size'], shuffle=True)\n","    test_loader = DataLoader(TensorDataset(test_data, test_labels), batch_size=1000)\n","    clean_test_loader = DataLoader(TensorDataset(clean_test_data, clean_test_labels), batch_size=1000)\n","    return train_loader, test_loader, clean_test_loader\n","\n","\n","# ============================================================================\n","# GRU-BASED RECURRENT NETWORK ARCHITECTURE WITH MS PROTECTION PARAMETERS\n","# ============================================================================\n","class RecurrentStressNetwork(nn.Module):\n","    \"\"\"\n","    GRUCell-based recurrent network with per-step modulations.\n","    Preserves original per-layer logic (stress noise, gain, inhibition, MS protection).\n","\n","    Architecture:\n","    - GRUCell processes input at each time step\n","    - Per-step modulations: stress noise, gain scaling, inhibition, MS bias damping\n","    - Hidden state carries memory across steps (enables instability compounding)\n","    - Final hidden state passed through output layer\n","    \"\"\"\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.hidden_size = CONFIG['gru_hidden_size']\n","        self.seq_len = CONFIG['seq_len']\n","\n","        # GRU cell for recurrent processing\n","        self.gru_cell = nn.GRUCell(CONFIG['input_dim'], self.hidden_size)\n","\n","        # Output layer\n","        self.fc = nn.Linear(self.hidden_size, CONFIG['output_dim'])\n","\n","        # Activation functions\n","        self.relu = nn.ReLU()\n","        self.tanh = nn.Tanh()\n","\n","        # Core modulation parameters (same as original)\n","        self.stress_level = 0.0\n","        self.inhibition_strength = 1.0\n","        self.use_tanh = False\n","        self.gain_multiplier = 1.0\n","\n","        # Mood Stabilizer (MS) parameters (same as original)\n","        self.ms_protection_level = 0.0\n","        self.lingering_ms_decay_rate = 0.0\n","\n","        # Weight layers for pruning manager compatibility\n","        self.weight_layers = ['gru_cell.weight_ih', 'gru_cell.weight_hh', 'fc']\n","\n","    def set_stress(self, level: float):\n","        self.stress_level = level\n","\n","    def set_inhibition(self, strength: float, use_tanh: bool = False):\n","        self.inhibition_strength = strength\n","        self.use_tanh = use_tanh\n","\n","    def set_gain(self, gain: float):\n","        self.gain_multiplier = gain\n","\n","    def set_ms_protection(self, level: float, decay_rate: float = 0.0):\n","        self.ms_protection_level = max(0.0, min(1.0, level))\n","        self.lingering_ms_decay_rate = decay_rate\n","\n","    def decay_ms_protection(self):\n","        if self.lingering_ms_decay_rate > 0:\n","            self.ms_protection_level = max(0.0, self.ms_protection_level - self.lingering_ms_decay_rate)\n","\n","    def reset_antidepressant_effects(self):\n","        self.gain_multiplier = 1.0\n","        self.inhibition_strength = 1.0\n","        self.use_tanh = False\n","        self.stress_level = 0.0\n","\n","    def get_effective_gain(self) -> float:\n","        if self.ms_protection_level > 0:\n","            max_allowed = CONFIG['ms_gain_cap'] + (1.0 - self.ms_protection_level) * (self.gain_multiplier - CONFIG['ms_gain_cap'])\n","            return min(self.gain_multiplier, max(CONFIG['ms_gain_cap'], max_allowed))\n","        return self.gain_multiplier\n","\n","    def reduce_stress_gradually(self, epoch: int, total_epochs: int, initial_stress: float = 0.5, final_stress: float = 0.0):\n","        progress = epoch / max(total_epochs - 1, 1)\n","        self.stress_level = initial_stress + progress * (final_stress - initial_stress)\n","\n","    def increase_gain_gradually(self, epoch: int, total_epochs: int, initial_gain: float = 1.0, max_gain: float = 1.6):\n","        progress = epoch / max(total_epochs - 1, 1)\n","        self.gain_multiplier = initial_gain + progress * (max_gain - initial_gain)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Forward pass with per-step modulations.\n","        x: [batch, seq_len, input_dim]\n","        \"\"\"\n","        batch_size = x.size(0)\n","        h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n","\n","        activation = self.tanh if self.use_tanh else self.relu\n","        effective_gain = self.get_effective_gain()\n","\n","        for t in range(x.size(1)):\n","            # Apply gain to input\n","            inp = x[:, t, :] * effective_gain\n","\n","            # Add stress noise to input (per-step, like per-layer in original)\n","            if self.stress_level > 0.0:\n","                inp = inp + torch.randn_like(inp) * self.stress_level\n","\n","            # GRU cell update\n","            h = self.gru_cell(inp, h)\n","\n","            # Apply inhibition (per-step modulation)\n","            h = h * self.inhibition_strength\n","\n","            # Apply MS protection bias (per-step)\n","            if self.ms_protection_level > 0.0:\n","                h = h - CONFIG['ms_inhib_bias_strength'] * self.ms_protection_level\n","\n","            # Post-activation (optional, matches original ReLU/Tanh per layer)\n","            h = activation(h)\n","\n","        return self.fc(h)\n","\n","    def forward_with_biased_noise(self, x: torch.Tensor, internal_sigma: float = 1.0, bias: float = 1.0) -> torch.Tensor:\n","        \"\"\"\n","        Forward pass with biased noise for mania testing.\n","        Bias compounds over recurrent steps -> better instability modeling.\n","        x: [batch, seq_len, input_dim]\n","        \"\"\"\n","        batch_size = x.size(0)\n","        h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n","\n","        activation = self.tanh if self.use_tanh else self.relu\n","        effective_gain = self.get_effective_gain()\n","\n","        # MS protection dampens bias\n","        bias_multiplier = 1.0 - (CONFIG['ms_bias_damping_factor'] * self.ms_protection_level)\n","        effective_bias = bias * bias_multiplier\n","\n","        for t in range(x.size(1)):\n","            # Apply gain to input\n","            inp = x[:, t, :] * effective_gain\n","\n","            # GRU cell update\n","            h = self.gru_cell(inp, h)\n","\n","            # Add biased noise AFTER cell update (compounds recurrently -> better instability)\n","            h = h + (torch.randn_like(h) * internal_sigma + effective_bias)\n","\n","            # Apply inhibition\n","            h = h * self.inhibition_strength\n","\n","            # Apply MS protection bias\n","            if self.ms_protection_level > 0.0:\n","                h = h - CONFIG['ms_inhib_bias_strength'] * self.ms_protection_level\n","\n","            # Post-activation\n","            h = activation(h)\n","\n","        return self.fc(h)\n","\n","    def count_parameters(self) -> Tuple[int, int]:\n","        total = sum(p.numel() for p in self.parameters())\n","        nonzero = sum((p != 0).sum().item() for p in self.parameters())\n","        return total, nonzero\n","\n","\n","# Alias for backward compatibility\n","StressAwareNetwork = RecurrentStressNetwork\n","\n","\n","# ============================================================================\n","# PRUNING MANAGER WITH SCAR MASKS (KINDLING ARCHITECTURE)\n","# ============================================================================\n","class PruningManager:\n","    \"\"\"\n","    Extended PruningManager with permanent scar masks for kindling.\n","    Now works with GRU weights (weight_ih, weight_hh) in addition to linear layers.\n","\n","    Architecture changes for kindling:\n","    - scar_masks: Binary masks tracking permanently damaged (scarred) connections\n","    - Scarred positions cannot be regrown (gradient_guided_regrow respects scars)\n","    - prune_by_magnitude with permanent=True updates scar_masks\n","    \"\"\"\n","\n","    def __init__(self, model: RecurrentStressNetwork, train_loader: DataLoader):\n","        self.model = model\n","        self.train_loader = train_loader\n","        self.masks = {}\n","        self.scar_masks = {}  # Permanent damage tracking\n","        self.gradient_buffer = {}\n","\n","        for name, param in model.named_parameters():\n","            if 'weight' in name and param.dim() >= 2:\n","                self.masks[name] = torch.ones_like(param, dtype=torch.float32)\n","                self.scar_masks[name] = torch.zeros_like(param, dtype=torch.float32)  # 1 = scarred\n","                self.gradient_buffer[name] = torch.zeros_like(param)\n","\n","    def prune_by_magnitude(self, sparsity: float, per_layer: bool = True, permanent: bool = False) -> Dict[str, Dict]:\n","        \"\"\"\n","        Prune by magnitude. If permanent=True, mark pruned positions as scars.\n","        \"\"\"\n","        stats = {}\n","        for name, param in self.model.named_parameters():\n","            if name in self.masks:\n","                # Only consider non-scarred positions for pruning\n","                available_mask = (self.scar_masks[name] == 0).float()\n","                weights = param.data.abs() * available_mask\n","\n","                # Get threshold from available weights only\n","                available_weights = weights[available_mask > 0]\n","                if available_weights.numel() == 0:\n","                    stats[name] = {'kept': 0, 'total': self.masks[name].numel(), 'actual_sparsity': 1.0}\n","                    continue\n","\n","                threshold = torch.quantile(available_weights.flatten(), sparsity)\n","                new_prune_mask = (weights >= threshold).float()\n","\n","                # Combine with existing mask\n","                self.masks[name] = new_prune_mask * (1 - self.scar_masks[name])\n","                param.data *= self.masks[name]\n","\n","                if permanent:\n","                    # Mark newly pruned positions as permanent scars\n","                    newly_pruned = (new_prune_mask == 0) * available_mask\n","                    self.scar_masks[name] = torch.clamp(self.scar_masks[name] + newly_pruned, 0, 1)\n","\n","                kept = self.masks[name].sum().item()\n","                total = self.masks[name].numel()\n","                stats[name] = {'kept': int(kept), 'total': total, 'actual_sparsity': 1 - kept/total}\n","        return stats\n","\n","    def apply_episode_scar(self, base_sparsity: float, severity_factor: float = 1.0) -> Dict[str, Dict]:\n","        \"\"\"\n","        Apply uniform scarring upon manic episode. Severity scales the base sparsity.\n","        This is the kindling mechanism: each episode causes permanent damage.\n","        \"\"\"\n","        effective_sparsity = base_sparsity * severity_factor\n","        effective_sparsity = min(0.2, max(0.02, effective_sparsity))  # Clamp reasonable range\n","\n","        stats = {}\n","        for name, param in self.model.named_parameters():\n","            if name in self.masks:\n","                # Only scar currently active (non-zero, non-scarred) positions\n","                active_mask = (self.masks[name] > 0) * (self.scar_masks[name] == 0)\n","                active_weights = param.data.abs() * active_mask.float()\n","\n","                active_values = active_weights[active_mask]\n","                if active_values.numel() == 0:\n","                    stats[name] = {'scarred': 0, 'total_scars': self.scar_masks[name].sum().item()}\n","                    continue\n","\n","                # Prune lowest magnitude among active connections\n","                num_to_scar = max(1, int(effective_sparsity * active_values.numel()))\n","                threshold = torch.kthvalue(active_values, min(num_to_scar, active_values.numel())).values\n","\n","                new_scars = (active_weights <= threshold) * active_mask\n","                self.scar_masks[name] = torch.clamp(self.scar_masks[name] + new_scars.float(), 0, 1)\n","                self.masks[name] = self.masks[name] * (1 - new_scars.float())\n","                param.data *= self.masks[name]\n","\n","                stats[name] = {\n","                    'scarred': new_scars.sum().item(),\n","                    'total_scars': self.scar_masks[name].sum().item()\n","                }\n","        return stats\n","\n","    def _accumulate_gradients(self, num_batches: int = 30):\n","        model = self.model\n","        loss_fn = nn.CrossEntropyLoss()\n","        for name in self.gradient_buffer:\n","            self.gradient_buffer[name].zero_()\n","        model.train()\n","        original_stress = model.stress_level\n","        original_gain = model.gain_multiplier\n","        model.set_stress(0.0)\n","        model.set_gain(1.0)\n","        batch_count = 0\n","        for x, y in self.train_loader:\n","            if batch_count >= num_batches:\n","                break\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            loss = loss_fn(model(x), y)\n","            loss.backward()\n","            with torch.no_grad():\n","                for name, param in model.named_parameters():\n","                    if name in self.masks:\n","                        # Only accumulate for pruned, non-scarred positions\n","                        pruned_mask = (self.masks[name] == 0).float()\n","                        non_scarred = (self.scar_masks[name] == 0).float()\n","                        self.gradient_buffer[name] += param.grad.abs() * pruned_mask * non_scarred\n","            model.zero_grad()\n","            batch_count += 1\n","        model.set_stress(original_stress)\n","        model.set_gain(original_gain)\n","\n","    def gradient_guided_regrow(self, regrow_fraction: float, init_scale: float = None) -> Dict[str, Dict]:\n","        \"\"\"\n","        Regrow connections, respecting scar masks (cannot regrow scarred positions).\n","        \"\"\"\n","        if init_scale is None:\n","            init_scale = CONFIG['regrow_init_scale']\n","        self._accumulate_gradients(num_batches=CONFIG['gradient_accumulation_batches'])\n","        stats = {}\n","        for name, param in self.model.named_parameters():\n","            if name not in self.masks:\n","                continue\n","            mask = self.masks[name]\n","            scar_mask = self.scar_masks[name]\n","\n","            # Only consider pruned AND non-scarred positions for regrowth\n","            regrowable = (mask == 0) & (scar_mask == 0)\n","            num_regrowable = regrowable.sum().item()\n","\n","            if num_regrowable == 0:\n","                stats[name] = {'regrown': 0, 'still_pruned': 0, 'scarred': scar_mask.sum().item()}\n","                continue\n","\n","            gradient_scores = self.gradient_buffer[name][regrowable]\n","            num_regrow = max(1, int(regrow_fraction * num_regrowable))\n","            num_regrow = min(num_regrow, gradient_scores.numel())\n","\n","            _, top_indices = torch.topk(gradient_scores.flatten(), num_regrow)\n","            flat_regrowable_indices = torch.where(regrowable.flatten())[0]\n","            regrow_flat_indices = flat_regrowable_indices[top_indices]\n","\n","            flat_mask = mask.flatten()\n","            flat_param = param.data.flatten()\n","            flat_mask[regrow_flat_indices] = 1.0\n","            flat_param[regrow_flat_indices] = torch.randn(num_regrow, device=param.device) * init_scale\n","\n","            self.masks[name] = flat_mask.view_as(mask)\n","            param.data = flat_param.view_as(param)\n","\n","            stats[name] = {\n","                'regrown': num_regrow,\n","                'still_pruned': int(num_regrowable - num_regrow),\n","                'scarred': scar_mask.sum().item()\n","            }\n","        return stats\n","\n","    def apply_masks(self):\n","        with torch.no_grad():\n","            for name, param in self.model.named_parameters():\n","                if name in self.masks:\n","                    param.data *= self.masks[name]\n","\n","    def get_sparsity(self) -> float:\n","        total = sum(m.numel() for m in self.masks.values())\n","        zeros = sum((m == 0).sum().item() for m in self.masks.values())\n","        return zeros / total if total > 0 else 0.0\n","\n","    def get_scar_fraction(self) -> float:\n","        total = sum(m.numel() for m in self.scar_masks.values())\n","        scarred = sum(m.sum().item() for m in self.scar_masks.values())\n","        return scarred / total if total > 0 else 0.0\n","\n","    def clone_masks(self) -> Dict[str, torch.Tensor]:\n","        return {k: v.clone() for k, v in self.masks.items()}\n","\n","    def clone_scar_masks(self) -> Dict[str, torch.Tensor]:\n","        return {k: v.clone() for k, v in self.scar_masks.items()}\n","\n","    def apply_early_adversity(self, max_scar_fraction: float, seed: int) -> float:\n","        \"\"\"\n","        Apply random early adversity scarring (uniform across treatments).\n","        Returns the fraction of parameters scarred.\n","        \"\"\"\n","        rng = np.random.RandomState(seed)\n","        scar_fraction = rng.uniform(0.0, max_scar_fraction)\n","\n","        for name, param in self.model.named_parameters():\n","            if name in self.masks:\n","                num_params = param.numel()\n","                num_to_scar = int(scar_fraction * num_params)\n","                if num_to_scar > 0:\n","                    flat_scar = self.scar_masks[name].flatten()\n","                    flat_mask = self.masks[name].flatten()\n","                    flat_param = param.data.flatten()\n","\n","                    # Random positions to scar\n","                    available_idx = torch.where(flat_scar == 0)[0]\n","                    if len(available_idx) > num_to_scar:\n","                        perm = torch.randperm(len(available_idx))[:num_to_scar]\n","                        scar_idx = available_idx[perm]\n","                        flat_scar[scar_idx] = 1.0\n","                        flat_mask[scar_idx] = 0.0\n","                        flat_param[scar_idx] = 0.0\n","\n","                    self.scar_masks[name] = flat_scar.view_as(self.scar_masks[name])\n","                    self.masks[name] = flat_mask.view_as(self.masks[name])\n","                    param.data = flat_param.view_as(param)\n","\n","        return scar_fraction\n","\n","\n","# ============================================================================\n","# TRAINING FUNCTIONS\n","# ============================================================================\n","def train(model: RecurrentStressNetwork, train_loader: DataLoader, epochs: int = 15, lr: float = 0.001,\n","          pruning_manager: PruningManager = None) -> List[float]:\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    loss_fn = nn.CrossEntropyLoss()\n","    losses = []\n","    original_stress = model.stress_level\n","    model.set_stress(0.0)\n","    for epoch in range(epochs):\n","        model.train()\n","        epoch_loss = 0.0\n","        for x, y in train_loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            optimizer.zero_grad()\n","            loss = loss_fn(model(x), y)\n","            loss.backward()\n","            optimizer.step()\n","            if pruning_manager:\n","                pruning_manager.apply_masks()\n","            epoch_loss += loss.item()\n","        losses.append(epoch_loss / len(train_loader))\n","    model.set_stress(original_stress)\n","    return losses\n","\n","\n","def train_with_stress_and_gain_schedule(model: RecurrentStressNetwork, train_loader: DataLoader, epochs: int, lr: float,\n","                                         initial_stress: float, final_stress: float = 0.0,\n","                                         initial_gain: float = 1.0, max_gain: float = 1.6,\n","                                         pruning_manager: PruningManager = None) -> List[float]:\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    loss_fn = nn.CrossEntropyLoss()\n","    losses = []\n","    for epoch in range(epochs):\n","        model.reduce_stress_gradually(epoch, epochs, initial_stress, final_stress)\n","        model.increase_gain_gradually(epoch, epochs, initial_gain, max_gain)\n","        model.train()\n","        epoch_loss = 0.0\n","        for x, y in train_loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            optimizer.zero_grad()\n","            loss = loss_fn(model(x), y)\n","            loss.backward()\n","            optimizer.step()\n","            if pruning_manager:\n","                pruning_manager.apply_masks()\n","            epoch_loss += loss.item()\n","        losses.append(epoch_loss / len(train_loader))\n","    model.set_stress(0.0)\n","    return losses\n","\n","\n","# ============================================================================\n","# EVALUATION FUNCTIONS\n","# ============================================================================\n","def evaluate(model: RecurrentStressNetwork, loader: DataLoader, input_noise: float = 0.0, internal_stress: float = 0.0) -> float:\n","    model.eval()\n","    model.set_stress(internal_stress)\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            if input_noise > 0:\n","                x = x + torch.randn_like(x) * input_noise\n","            correct += (model(x).argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","    model.set_stress(0.0)\n","    return 100.0 * correct / total\n","\n","\n","def evaluate_biased_stress(model: RecurrentStressNetwork, loader: DataLoader, input_noise: float = 0.0,\n","                           internal_sigma: float = 1.0, bias: float = 1.0) -> float:\n","    model.eval()\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            if input_noise > 0:\n","                x = x + torch.randn_like(x) * input_noise\n","            out = model.forward_with_biased_noise(x, internal_sigma, bias)\n","            correct += (out.argmax(dim=1) == y).sum().item()\n","            total += y.size(0)\n","    return 100.0 * correct / total\n","\n","\n","def get_avg_activation_magnitude(model: RecurrentStressNetwork, loader: DataLoader) -> float:\n","    \"\"\"\n","    Compute average activation magnitude across time steps.\n","    Updated for GRU architecture.\n","    \"\"\"\n","    model.eval()\n","    all_acts = []\n","\n","    activation = model.tanh if model.use_tanh else model.relu\n","\n","    with torch.no_grad():\n","        for x, _ in loader:\n","            x = x.to(DEVICE)\n","            batch_size = x.size(0)\n","            h = torch.zeros(batch_size, model.hidden_size, device=x.device)\n","\n","            for t in range(x.size(1)):\n","                inp = x[:, t, :] * model.gain_multiplier\n","                h = model.gru_cell(inp, h)\n","                h = h * model.inhibition_strength\n","                h = activation(h)\n","                all_acts.append(torch.mean(torch.abs(h)).item())\n","\n","    return np.mean(all_acts) if all_acts else 0.0\n","\n","\n","# ============================================================================\n","# TREATMENT PROTOCOLS\n","# ============================================================================\n","def ketamine_treatment(model: RecurrentStressNetwork, pruning_mgr: PruningManager, train_loader: DataLoader) -> Dict:\n","    model.set_gain(CONFIG['ketamine_gain'])\n","    pruning_mgr.gradient_guided_regrow(regrow_fraction=CONFIG['comparison_ketamine_regrow'])\n","    train(model, train_loader, epochs=CONFIG['comparison_ketamine_epochs'], lr=CONFIG['finetune_lr'], pruning_manager=pruning_mgr)\n","    return {'final_sparsity': pruning_mgr.get_sparsity(), 'final_gain': model.gain_multiplier}\n","\n","\n","def ssri_treatment(model: RecurrentStressNetwork, pruning_mgr: PruningManager, train_loader: DataLoader) -> Dict:\n","    train_with_stress_and_gain_schedule(\n","        model, train_loader, epochs=CONFIG['comparison_ssri_epochs'], lr=CONFIG['monoaminergic_lr'],\n","        initial_stress=CONFIG['monoaminergic_initial_stress'], final_stress=0.0,\n","        initial_gain=1.0, max_gain=CONFIG['ssri_max_gain'], pruning_manager=pruning_mgr\n","    )\n","    return {'final_sparsity': pruning_mgr.get_sparsity(), 'final_gain': model.gain_multiplier}\n","\n","\n","def neurosteroid_treatment(model: RecurrentStressNetwork, pruning_mgr: PruningManager, train_loader: DataLoader) -> Dict:\n","    model.set_inhibition(CONFIG['neurosteroid_inhibition_strength'], CONFIG['neurosteroid_use_tanh'])\n","    model.set_gain(CONFIG['neurosteroid_gain'])\n","    train(model, train_loader, epochs=CONFIG['neurosteroid_consolidation_epochs'], lr=CONFIG['finetune_lr'], pruning_manager=pruning_mgr)\n","    return {'final_sparsity': pruning_mgr.get_sparsity(), 'final_gain': model.gain_multiplier,\n","            'effective_scale': model.inhibition_strength * model.gain_multiplier}\n","\n","\n","# ============================================================================\n","# KINDLING SIMULATION (MULTI-CYCLE WITH UNIFORM SCARRING)\n","# ============================================================================\n","def simulate_kindling(\n","    model_state: Dict[str, torch.Tensor],\n","    mask_state: Dict[str, torch.Tensor],\n","    scar_state: Dict[str, torch.Tensor],\n","    treatment_type: str,\n","    train_loader: DataLoader,\n","    test_loader: DataLoader,\n","    seed: int\n",") -> Dict:\n","    \"\"\"\n","    Simulate kindling: progressive sensitization through repeated manic episodes.\n","\n","    Architecture mechanism:\n","    - Each relapse triggers uniform base scarring (same for all treatments)\n","    - Severity factor computed from current gain and activation magnitude (emergent)\n","    - Scars accumulate across cycles (permanent mask positions)\n","    - Trigger bias weakens over cycles to test spontaneous episode emergence\n","    - Treatment differences emerge from:\n","      - Ketamine: gradient-guided regrowth partially compensates for scars\n","      - SSRI: high gain amplifies severity factor\n","      - Neurosteroid: low gain/inhibition reduces severity factor\n","    \"\"\"\n","\n","    num_cycles = CONFIG['kindling_num_cycles']\n","    initial_bias = CONFIG['kindling_initial_trigger_bias']\n","    final_bias = CONFIG['kindling_final_trigger_bias']\n","\n","    results = {\n","        'cycles': [],\n","        'biased_accuracies': [],\n","        'trigger_biases': [],\n","        'relapsed': [],\n","        'scar_fractions': [],\n","        'sparsities': [],\n","        'severity_factors': [],\n","        'activation_magnitudes': [],\n","        'effective_gains': []\n","    }\n","\n","    # Create model from state\n","    model = RecurrentStressNetwork().to(DEVICE)\n","    model.load_state_dict(copy.deepcopy(model_state))\n","\n","    mgr = PruningManager(model, train_loader)\n","    mgr.masks = {k: v.clone() for k, v in mask_state.items()}\n","    mgr.scar_masks = {k: v.clone() for k, v in scar_state.items()}\n","    mgr.apply_masks()\n","\n","    # Apply treatment-specific parameters\n","    if treatment_type == 'ketamine':\n","        model.set_gain(CONFIG['ketamine_gain'])\n","    elif treatment_type == 'ssri':\n","        model.set_gain(CONFIG['ssri_max_gain'])\n","    elif treatment_type == 'neurosteroid':\n","        model.set_inhibition(CONFIG['neurosteroid_inhibition_strength'], CONFIG['neurosteroid_use_tanh'])\n","        model.set_gain(CONFIG['neurosteroid_gain'])\n","\n","    for cycle in range(num_cycles):\n","        # Calculate weakening trigger bias (linear interpolation)\n","        progress = cycle / max(num_cycles - 1, 1)\n","        trigger_bias = initial_bias + progress * (final_bias - initial_bias)\n","\n","        # Inter-episode maintenance (treatment-specific recovery)\n","        if cycle > 0:\n","            if treatment_type == 'ketamine':\n","                # Ketamine: attempt regrowth during maintenance\n","                mgr.gradient_guided_regrow(regrow_fraction=0.3)\n","                train(model, train_loader, epochs=CONFIG['kindling_inter_episode_maintenance_epochs'],\n","                      lr=CONFIG['finetune_lr'], pruning_manager=mgr)\n","            elif treatment_type == 'ssri':\n","                # SSRI: standard maintenance, no structural repair\n","                train(model, train_loader, epochs=CONFIG['kindling_inter_episode_maintenance_epochs'],\n","                      lr=CONFIG['monoaminergic_lr'], pruning_manager=mgr)\n","            elif treatment_type == 'neurosteroid':\n","                # Neurosteroid: maintenance with inhibition active\n","                train(model, train_loader, epochs=CONFIG['kindling_inter_episode_maintenance_epochs'],\n","                      lr=CONFIG['finetune_lr'], pruning_manager=mgr)\n","\n","        # Measure current architectural state\n","        current_gain = model.get_effective_gain()\n","        current_act_mag = get_avg_activation_magnitude(model, test_loader)\n","        current_sparsity = mgr.get_sparsity()\n","        current_scar_fraction = mgr.get_scar_fraction()\n","\n","        # Manic trigger test with current bias\n","        biased_acc = evaluate_biased_stress(\n","            model, test_loader,\n","            internal_sigma=CONFIG['mania_test_sigma'],\n","            bias=trigger_bias\n","        )\n","\n","        # Determine relapse\n","        relapsed = biased_acc < CONFIG['manic_relapse_threshold']\n","\n","        # Compute severity factor (emergent from architecture)\n","        # Higher gain and higher activation magnitude = more severe episode = more scarring\n","        severity_factor = 1.0 + (current_gain - 1.0) + (current_act_mag - 0.1) * 2.0\n","        severity_factor = max(CONFIG['kindling_severity_min'],\n","                            min(CONFIG['kindling_severity_max'], severity_factor))\n","\n","        # Apply uniform scarring if relapsed\n","        if relapsed:\n","            mgr.apply_episode_scar(\n","                base_sparsity=CONFIG['kindling_base_scar_sparsity'],\n","                severity_factor=severity_factor\n","            )\n","\n","        # Record results\n","        results['cycles'].append(cycle)\n","        results['trigger_biases'].append(trigger_bias)\n","        results['biased_accuracies'].append(biased_acc)\n","        results['relapsed'].append(relapsed)\n","        results['scar_fractions'].append(mgr.get_scar_fraction())\n","        results['sparsities'].append(mgr.get_sparsity())\n","        results['severity_factors'].append(severity_factor)\n","        results['activation_magnitudes'].append(current_act_mag)\n","        results['effective_gains'].append(current_gain)\n","\n","    # Summary statistics\n","    results['total_relapses'] = sum(results['relapsed'])\n","    results['final_scar_fraction'] = results['scar_fractions'][-1]\n","    results['final_sparsity'] = results['sparsities'][-1]\n","\n","    # Autonomy test: relapse at minimal trigger\n","    final_acc_minimal = evaluate_biased_stress(\n","        model, test_loader,\n","        internal_sigma=CONFIG['mania_test_sigma'],\n","        bias=0.3  # Very weak trigger\n","    )\n","    results['autonomy_test_accuracy'] = final_acc_minimal\n","    results['autonomy_achieved'] = final_acc_minimal < CONFIG['kindling_autonomy_threshold']\n","\n","    # First cycle of relapse at weak trigger\n","    weak_trigger_relapses = [i for i, (b, r) in enumerate(zip(results['trigger_biases'], results['relapsed']))\n","                             if b <= 1.0 and r]\n","    results['first_weak_trigger_relapse'] = weak_trigger_relapses[0] if weak_trigger_relapses else None\n","\n","    return results\n","\n","\n","# ============================================================================\n","# LONGITUDINAL MANIC RELAPSE SIMULATION\n","# ============================================================================\n","def simulate_longitudinal_manic_relapse(\n","    model_state: Dict[str, torch.Tensor],\n","    mask_state: Dict[str, torch.Tensor],\n","    treatment_type: str,\n","    treatment_params: Dict,\n","    train_loader: DataLoader,\n","    test_loader: DataLoader\n",") -> Dict:\n","    \"\"\"\n","    Simulate longitudinal manic relapse after medication discontinuation.\n","    \"\"\"\n","    decay_rates = {\n","        'ketamine': CONFIG['ketamine_ms_decay_rate'],\n","        'ssri': CONFIG['ssri_ms_decay_rate'],\n","        'neurosteroid': CONFIG['neurosteroid_ms_decay_rate']\n","    }\n","    ms_decay_rate = decay_rates[treatment_type]\n","\n","    results = {\n","        'maintenance_durations': [],\n","        'biased_stress_accuracies': [],\n","        'ms_protection_at_test': [],\n","        'relapsed': [],\n","        'effective_gain_at_test': []\n","    }\n","\n","    for duration in CONFIG['maintenance_durations']:\n","        model = RecurrentStressNetwork().to(DEVICE)\n","        model.load_state_dict(copy.deepcopy(model_state))\n","\n","        mgr = PruningManager(model, train_loader)\n","        mgr.masks = {k: v.clone() for k, v in mask_state.items()}\n","        mgr.apply_masks()\n","\n","        if treatment_type == 'ketamine':\n","            model.set_gain(treatment_params.get('final_gain', CONFIG['ketamine_gain']))\n","        elif treatment_type == 'ssri':\n","            model.set_gain(treatment_params.get('final_gain', CONFIG['ssri_max_gain']))\n","        elif treatment_type == 'neurosteroid':\n","            model.set_inhibition(CONFIG['neurosteroid_inhibition_strength'], CONFIG['neurosteroid_use_tanh'])\n","            model.set_gain(treatment_params.get('final_gain', CONFIG['neurosteroid_gain']))\n","\n","        model.set_ms_protection(CONFIG['ms_max_protection'], ms_decay_rate)\n","        train(model, train_loader, epochs=duration, lr=CONFIG['maintenance_lr'], pruning_manager=mgr)\n","        model.reset_antidepressant_effects()\n","\n","        for _ in range(CONFIG['post_discontinuation_steps']):\n","            model.decay_ms_protection()\n","\n","        final_ms_protection = model.ms_protection_level\n","        effective_gain = model.get_effective_gain()\n","\n","        biased_acc = evaluate_biased_stress(\n","            model, test_loader,\n","            internal_sigma=CONFIG['mania_test_sigma'],\n","            bias=CONFIG['mania_test_bias']\n","        )\n","\n","        relapsed = biased_acc < CONFIG['manic_relapse_threshold']\n","\n","        results['maintenance_durations'].append(duration)\n","        results['biased_stress_accuracies'].append(biased_acc)\n","        results['ms_protection_at_test'].append(final_ms_protection)\n","        results['relapsed'].append(relapsed)\n","        results['effective_gain_at_test'].append(effective_gain)\n","\n","    results['relapse_count'] = sum(results['relapsed'])\n","    results['total_tests'] = len(results['relapsed'])\n","    results['relapse_probability'] = (results['relapse_count'] / results['total_tests']) * 100\n","    results['mean_biased_acc'] = np.mean(results['biased_stress_accuracies'])\n","    results['std_biased_acc'] = np.std(results['biased_stress_accuracies'])\n","    results['ms_decay_rate'] = ms_decay_rate\n","\n","    return results\n","\n","\n","# ============================================================================\n","# SINGLE SEED EXPERIMENT\n","# ============================================================================\n","def run_single_seed(seed: int) -> Dict[str, Dict]:\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","\n","    train_loader, test_loader, clean_test_loader = create_data_loaders(seed)\n","\n","    # Train and prune base model\n","    base_model = RecurrentStressNetwork().to(DEVICE)\n","    train(base_model, train_loader, epochs=CONFIG['baseline_epochs'], lr=CONFIG['baseline_lr'])\n","    base_pruning_mgr = PruningManager(base_model, train_loader)\n","    base_pruning_mgr.prune_by_magnitude(sparsity=CONFIG['prune_sparsity'])\n","\n","    # Apply early adversity (uniform random scarring)\n","    early_adversity_fraction = base_pruning_mgr.apply_early_adversity(\n","        CONFIG['early_adversity_max_scar'], seed\n","    )\n","\n","    base_state_dict = {k: v.clone() for k, v in base_model.state_dict().items()}\n","    base_masks = {k: v.clone() for k, v in base_pruning_mgr.masks.items()}\n","    base_scars = base_pruning_mgr.clone_scar_masks()\n","\n","    results = {'early_adversity_fraction': early_adversity_fraction}\n","\n","    # Untreated\n","    untreated_results = {\n","        'sparsity': base_pruning_mgr.get_sparsity() * 100,\n","        'scar_fraction': base_pruning_mgr.get_scar_fraction() * 100,\n","        'gain': 1.0,\n","        'clean': evaluate(base_model, clean_test_loader),\n","        'standard': evaluate(base_model, test_loader),\n","        'combined': evaluate(base_model, test_loader, 1.0, 0.5),\n","        'biased_stress': evaluate_biased_stress(base_model, test_loader, internal_sigma=CONFIG['mania_test_sigma'], bias=CONFIG['mania_test_bias']),\n","        'activation_magnitude': get_avg_activation_magnitude(base_model, test_loader)\n","    }\n","    for stress_name, stress_level in CONFIG['extended_stress_levels'].items():\n","        untreated_results[f'stress_{stress_name}'] = evaluate(base_model, test_loader, 0.0, stress_level)\n","    results['untreated'] = untreated_results\n","\n","    # ========================================================================\n","    # KETAMINE TREATMENT\n","    # ========================================================================\n","    ketamine_model = RecurrentStressNetwork().to(DEVICE)\n","    ketamine_model.load_state_dict(copy.deepcopy(base_state_dict))\n","    ketamine_mgr = PruningManager(ketamine_model, train_loader)\n","    ketamine_mgr.masks = {k: v.clone() for k, v in base_masks.items()}\n","    ketamine_mgr.scar_masks = {k: v.clone() for k, v in base_scars.items()}\n","    ketamine_mgr.apply_masks()\n","    ketamine_stats = ketamine_treatment(ketamine_model, ketamine_mgr, train_loader)\n","\n","    ketamine_post_state = {k: v.clone() for k, v in ketamine_model.state_dict().items()}\n","    ketamine_post_masks = ketamine_mgr.clone_masks()\n","    ketamine_post_scars = ketamine_mgr.clone_scar_masks()\n","\n","    ketamine_results = {\n","        'sparsity': ketamine_mgr.get_sparsity() * 100,\n","        'scar_fraction': ketamine_mgr.get_scar_fraction() * 100,\n","        'gain': ketamine_model.gain_multiplier,\n","        'clean': evaluate(ketamine_model, clean_test_loader),\n","        'standard': evaluate(ketamine_model, test_loader),\n","        'combined': evaluate(ketamine_model, test_loader, 1.0, 0.5),\n","        'biased_stress': evaluate_biased_stress(ketamine_model, test_loader, internal_sigma=CONFIG['mania_test_sigma'], bias=CONFIG['mania_test_bias']),\n","        'activation_magnitude': get_avg_activation_magnitude(ketamine_model, test_loader)\n","    }\n","    for stress_name, stress_level in CONFIG['extended_stress_levels'].items():\n","        ketamine_results[f'stress_{stress_name}'] = evaluate(ketamine_model, test_loader, 0.0, stress_level)\n","\n","    # Longitudinal relapse\n","    ketamine_longitudinal = simulate_longitudinal_manic_relapse(\n","        ketamine_post_state, ketamine_post_masks, 'ketamine', ketamine_stats,\n","        train_loader, test_loader\n","    )\n","    ketamine_results['longitudinal'] = ketamine_longitudinal\n","\n","    # Kindling simulation\n","    ketamine_kindling = simulate_kindling(\n","        ketamine_post_state, ketamine_post_masks, ketamine_post_scars,\n","        'ketamine', train_loader, test_loader, seed\n","    )\n","    ketamine_results['kindling'] = ketamine_kindling\n","\n","    # Acute relapse\n","    pre_relapse = ketamine_results['combined']\n","    target_sparsity = min(ketamine_mgr.get_sparsity() + (1 - ketamine_mgr.get_sparsity()) * 0.40, 0.99)\n","    ketamine_mgr.prune_by_magnitude(sparsity=target_sparsity)\n","    ketamine_mgr.apply_masks()\n","    ketamine_results['relapse_drop'] = pre_relapse - evaluate(ketamine_model, test_loader, 1.0, 0.5)\n","    results['ketamine'] = ketamine_results\n","\n","    # ========================================================================\n","    # SSRI TREATMENT\n","    # ========================================================================\n","    ssri_model = RecurrentStressNetwork().to(DEVICE)\n","    ssri_model.load_state_dict(copy.deepcopy(base_state_dict))\n","    ssri_mgr = PruningManager(ssri_model, train_loader)\n","    ssri_mgr.masks = {k: v.clone() for k, v in base_masks.items()}\n","    ssri_mgr.scar_masks = {k: v.clone() for k, v in base_scars.items()}\n","    ssri_mgr.apply_masks()\n","    ssri_stats = ssri_treatment(ssri_model, ssri_mgr, train_loader)\n","\n","    ssri_post_state = {k: v.clone() for k, v in ssri_model.state_dict().items()}\n","    ssri_post_masks = ssri_mgr.clone_masks()\n","    ssri_post_scars = ssri_mgr.clone_scar_masks()\n","\n","    ssri_results = {\n","        'sparsity': ssri_mgr.get_sparsity() * 100,\n","        'scar_fraction': ssri_mgr.get_scar_fraction() * 100,\n","        'gain': ssri_model.gain_multiplier,\n","        'clean': evaluate(ssri_model, clean_test_loader),\n","        'standard': evaluate(ssri_model, test_loader),\n","        'combined': evaluate(ssri_model, test_loader, 1.0, 0.5),\n","        'biased_stress': evaluate_biased_stress(ssri_model, test_loader, internal_sigma=CONFIG['mania_test_sigma'], bias=CONFIG['mania_test_bias']),\n","        'activation_magnitude': get_avg_activation_magnitude(ssri_model, test_loader)\n","    }\n","    for stress_name, stress_level in CONFIG['extended_stress_levels'].items():\n","        ssri_results[f'stress_{stress_name}'] = evaluate(ssri_model, test_loader, 0.0, stress_level)\n","\n","    ssri_longitudinal = simulate_longitudinal_manic_relapse(\n","        ssri_post_state, ssri_post_masks, 'ssri', ssri_stats,\n","        train_loader, test_loader\n","    )\n","    ssri_results['longitudinal'] = ssri_longitudinal\n","\n","    ssri_kindling = simulate_kindling(\n","        ssri_post_state, ssri_post_masks, ssri_post_scars,\n","        'ssri', train_loader, test_loader, seed\n","    )\n","    ssri_results['kindling'] = ssri_kindling\n","\n","    pre_relapse = ssri_results['combined']\n","    target_sparsity = min(ssri_mgr.get_sparsity() + (1 - ssri_mgr.get_sparsity()) * 0.40, 0.99)\n","    ssri_mgr.prune_by_magnitude(sparsity=target_sparsity)\n","    ssri_mgr.apply_masks()\n","    ssri_results['relapse_drop'] = pre_relapse - evaluate(ssri_model, test_loader, 1.0, 0.5)\n","    results['ssri'] = ssri_results\n","\n","    # ========================================================================\n","    # NEUROSTEROID TREATMENT\n","    # ========================================================================\n","    neuro_model = RecurrentStressNetwork().to(DEVICE)\n","    neuro_model.load_state_dict(copy.deepcopy(base_state_dict))\n","    neuro_mgr = PruningManager(neuro_model, train_loader)\n","    neuro_mgr.masks = {k: v.clone() for k, v in base_masks.items()}\n","    neuro_mgr.scar_masks = {k: v.clone() for k, v in base_scars.items()}\n","    neuro_mgr.apply_masks()\n","    neuro_stats = neurosteroid_treatment(neuro_model, neuro_mgr, train_loader)\n","\n","    neuro_post_state = {k: v.clone() for k, v in neuro_model.state_dict().items()}\n","    neuro_post_masks = neuro_mgr.clone_masks()\n","    neuro_post_scars = neuro_mgr.clone_scar_masks()\n","\n","    neuro_results = {\n","        'sparsity': neuro_mgr.get_sparsity() * 100,\n","        'scar_fraction': neuro_mgr.get_scar_fraction() * 100,\n","        'gain': neuro_model.gain_multiplier,\n","        'effective_scale': neuro_model.inhibition_strength * neuro_model.gain_multiplier,\n","        'clean': evaluate(neuro_model, clean_test_loader),\n","        'standard': evaluate(neuro_model, test_loader),\n","        'combined': evaluate(neuro_model, test_loader, 1.0, 0.5),\n","        'biased_stress': evaluate_biased_stress(neuro_model, test_loader, internal_sigma=CONFIG['mania_test_sigma'], bias=CONFIG['mania_test_bias']),\n","        'activation_magnitude': get_avg_activation_magnitude(neuro_model, test_loader)\n","    }\n","    for stress_name, stress_level in CONFIG['extended_stress_levels'].items():\n","        neuro_results[f'stress_{stress_name}'] = evaluate(neuro_model, test_loader, 0.0, stress_level)\n","\n","    neuro_longitudinal = simulate_longitudinal_manic_relapse(\n","        neuro_post_state, neuro_post_masks, 'neurosteroid', neuro_stats,\n","        train_loader, test_loader\n","    )\n","    neuro_results['longitudinal'] = neuro_longitudinal\n","\n","    neuro_kindling = simulate_kindling(\n","        neuro_post_state, neuro_post_masks, neuro_post_scars,\n","        'neurosteroid', train_loader, test_loader, seed\n","    )\n","    neuro_results['kindling'] = neuro_kindling\n","\n","    # Off medication\n","    neuro_model.set_inhibition(1.0, False)\n","    neuro_model.set_gain(1.0)\n","    neuro_results['off_medication_combined'] = evaluate(neuro_model, test_loader, 1.0, 0.5)\n","    neuro_results['off_medication_extreme'] = evaluate(neuro_model, test_loader, 0.0, 2.5)\n","    neuro_results['off_medication_biased'] = evaluate_biased_stress(neuro_model, test_loader, internal_sigma=CONFIG['mania_test_sigma'], bias=CONFIG['mania_test_bias'])\n","    neuro_results['off_medication_activation'] = get_avg_activation_magnitude(neuro_model, test_loader)\n","\n","    neuro_model.set_inhibition(CONFIG['neurosteroid_inhibition_strength'], CONFIG['neurosteroid_use_tanh'])\n","    neuro_model.set_gain(CONFIG['neurosteroid_gain'])\n","    pre_relapse = neuro_results['combined']\n","    target_sparsity = min(neuro_mgr.get_sparsity() + (1 - neuro_mgr.get_sparsity()) * 0.40, 0.99)\n","    neuro_mgr.prune_by_magnitude(sparsity=target_sparsity)\n","    neuro_mgr.apply_masks()\n","    neuro_results['relapse_drop'] = pre_relapse - evaluate(neuro_model, test_loader, 1.0, 0.5)\n","    results['neurosteroid'] = neuro_results\n","\n","    return results\n","\n","\n","# ============================================================================\n","# AGGREGATE RESULTS\n","# ============================================================================\n","def aggregate_results(all_results: List[Dict[str, Dict]]) -> Dict:\n","    treatments = ['untreated', 'ketamine', 'ssri', 'neurosteroid']\n","    aggregated = {'treatments': {}, 'longitudinal': {}, 'kindling': {}}\n","\n","    # Aggregate early adversity\n","    early_adversity = [r['early_adversity_fraction'] for r in all_results if 'early_adversity_fraction' in r]\n","    aggregated['early_adversity'] = {\n","        'mean': np.mean(early_adversity) * 100,\n","        'std': np.std(early_adversity) * 100,\n","        'min': np.min(early_adversity) * 100,\n","        'max': np.max(early_adversity) * 100\n","    }\n","\n","    # Aggregate treatment metrics\n","    for treatment in treatments:\n","        metrics = defaultdict(list)\n","        for seed_result in all_results:\n","            if treatment in seed_result:\n","                for key, value in seed_result[treatment].items():\n","                    if isinstance(value, (int, float)):\n","                        metrics[key].append(value)\n","\n","        aggregated['treatments'][treatment] = {}\n","        for key, values in metrics.items():\n","            aggregated['treatments'][treatment][key] = {\n","                'mean': np.mean(values),\n","                'std': np.std(values),\n","                'min': np.min(values),\n","                'max': np.max(values)\n","            }\n","\n","    # Aggregate longitudinal data\n","    for treatment in ['ketamine', 'ssri', 'neurosteroid']:\n","        longitudinal_data = {\n","            'relapse_probabilities': [],\n","            'per_duration': defaultdict(lambda: {'biased_acc': [], 'ms_protection': [], 'relapsed': [], 'effective_gain': []})\n","        }\n","\n","        for seed_result in all_results:\n","            if treatment in seed_result and 'longitudinal' in seed_result[treatment]:\n","                long = seed_result[treatment]['longitudinal']\n","                longitudinal_data['relapse_probabilities'].append(long['relapse_probability'])\n","\n","                for i, dur in enumerate(long['maintenance_durations']):\n","                    longitudinal_data['per_duration'][dur]['biased_acc'].append(long['biased_stress_accuracies'][i])\n","                    longitudinal_data['per_duration'][dur]['ms_protection'].append(long['ms_protection_at_test'][i])\n","                    longitudinal_data['per_duration'][dur]['relapsed'].append(long['relapsed'][i])\n","                    longitudinal_data['per_duration'][dur]['effective_gain'].append(long['effective_gain_at_test'][i])\n","\n","        probs = longitudinal_data['relapse_probabilities']\n","        aggregated['longitudinal'][treatment] = {\n","            'relapse_probability_mean': np.mean(probs),\n","            'relapse_probability_std': np.std(probs),\n","            'relapse_probability_min': np.min(probs),\n","            'relapse_probability_max': np.max(probs),\n","            'ms_decay_rate': CONFIG[f'{treatment}_ms_decay_rate'],\n","            'per_duration': {}\n","        }\n","\n","        for dur in CONFIG['maintenance_durations']:\n","            dur_data = longitudinal_data['per_duration'][dur]\n","            if dur_data['biased_acc']:\n","                relapse_rate = (sum(dur_data['relapsed']) / len(dur_data['relapsed'])) * 100\n","                aggregated['longitudinal'][treatment]['per_duration'][dur] = {\n","                    'biased_acc_mean': np.mean(dur_data['biased_acc']),\n","                    'biased_acc_std': np.std(dur_data['biased_acc']),\n","                    'ms_protection_mean': np.mean(dur_data['ms_protection']),\n","                    'ms_protection_std': np.std(dur_data['ms_protection']),\n","                    'effective_gain_mean': np.mean(dur_data['effective_gain']),\n","                    'relapse_rate': relapse_rate,\n","                    'n_relapsed': sum(dur_data['relapsed']),\n","                    'n_total': len(dur_data['relapsed'])\n","                }\n","\n","    # Aggregate kindling data\n","    for treatment in ['ketamine', 'ssri', 'neurosteroid']:\n","        kindling_data = {\n","            'total_relapses': [],\n","            'final_scar_fractions': [],\n","            'autonomy_achieved': [],\n","            'autonomy_test_accuracies': [],\n","            'per_cycle': defaultdict(lambda: {\n","                'biased_acc': [], 'trigger_bias': [], 'relapsed': [],\n","                'scar_fraction': [], 'severity_factor': [], 'activation_mag': []\n","            })\n","        }\n","\n","        for seed_result in all_results:\n","            if treatment in seed_result and 'kindling' in seed_result[treatment]:\n","                kind = seed_result[treatment]['kindling']\n","                kindling_data['total_relapses'].append(kind['total_relapses'])\n","                kindling_data['final_scar_fractions'].append(kind['final_scar_fraction'])\n","                kindling_data['autonomy_achieved'].append(kind['autonomy_achieved'])\n","                kindling_data['autonomy_test_accuracies'].append(kind['autonomy_test_accuracy'])\n","\n","                for i, cycle in enumerate(kind['cycles']):\n","                    kindling_data['per_cycle'][cycle]['biased_acc'].append(kind['biased_accuracies'][i])\n","                    kindling_data['per_cycle'][cycle]['trigger_bias'].append(kind['trigger_biases'][i])\n","                    kindling_data['per_cycle'][cycle]['relapsed'].append(kind['relapsed'][i])\n","                    kindling_data['per_cycle'][cycle]['scar_fraction'].append(kind['scar_fractions'][i])\n","                    kindling_data['per_cycle'][cycle]['severity_factor'].append(kind['severity_factors'][i])\n","                    kindling_data['per_cycle'][cycle]['activation_mag'].append(kind['activation_magnitudes'][i])\n","\n","        aggregated['kindling'][treatment] = {\n","            'total_relapses_mean': np.mean(kindling_data['total_relapses']),\n","            'total_relapses_std': np.std(kindling_data['total_relapses']),\n","            'final_scar_fraction_mean': np.mean(kindling_data['final_scar_fractions']) * 100,\n","            'final_scar_fraction_std': np.std(kindling_data['final_scar_fractions']) * 100,\n","            'autonomy_rate': (sum(kindling_data['autonomy_achieved']) / len(kindling_data['autonomy_achieved'])) * 100,\n","            'autonomy_test_acc_mean': np.mean(kindling_data['autonomy_test_accuracies']),\n","            'autonomy_test_acc_std': np.std(kindling_data['autonomy_test_accuracies']),\n","            'per_cycle': {}\n","        }\n","\n","        for cycle in range(CONFIG['kindling_num_cycles']):\n","            cycle_data = kindling_data['per_cycle'][cycle]\n","            if cycle_data['biased_acc']:\n","                relapse_rate = (sum(cycle_data['relapsed']) / len(cycle_data['relapsed'])) * 100\n","                aggregated['kindling'][treatment]['per_cycle'][cycle] = {\n","                    'biased_acc_mean': np.mean(cycle_data['biased_acc']),\n","                    'biased_acc_std': np.std(cycle_data['biased_acc']),\n","                    'trigger_bias': np.mean(cycle_data['trigger_bias']),\n","                    'relapse_rate': relapse_rate,\n","                    'scar_fraction_mean': np.mean(cycle_data['scar_fraction']) * 100,\n","                    'scar_fraction_std': np.std(cycle_data['scar_fraction']) * 100,\n","                    'severity_factor_mean': np.mean(cycle_data['severity_factor']),\n","                    'activation_mag_mean': np.mean(cycle_data['activation_mag'])\n","                }\n","\n","    return aggregated\n","\n","\n","# ============================================================================\n","# MAIN EXPERIMENT\n","# ============================================================================\n","def run_multi_seed_experiment() -> Dict:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"  MULTI-MECHANISM ANTIDEPRESSANT COMPARISON EXPERIMENT\")\n","    print(\"  WITH MANIC CONVERSION + LONGITUDINAL RELAPSE + KINDLING\")\n","    print(\"  GRU-BASED RECURRENT ARCHITECTURE\")\n","    print(\"  Running across {} random seeds\".format(CONFIG['n_seeds']))\n","    print(\"=\"*80)\n","\n","    # Print architecture info\n","    print(f\"\\n  Architecture: GRUCell-based recurrent network\")\n","    print(f\"  Sequence length (depth analogue): {CONFIG['seq_len']}\")\n","    print(f\"  GRU hidden size: {CONFIG['gru_hidden_size']}\")\n","\n","    # Estimate parameter count\n","    input_dim = CONFIG['input_dim']\n","    hidden = CONFIG['gru_hidden_size']\n","    output_dim = CONFIG['output_dim']\n","    gru_params = 3 * hidden * (input_dim + hidden + 2)  # weight_ih, weight_hh, biases\n","    fc_params = hidden * output_dim + output_dim\n","    total_params = gru_params + fc_params\n","    print(f\"  Estimated total parameters: ~{total_params:,}\")\n","\n","    all_results = []\n","\n","    for seed in range(CONFIG['n_seeds']):\n","        print(f\"\\n  Seed {seed+1}/{CONFIG['n_seeds']}...\", end=\" \", flush=True)\n","        seed_results = run_single_seed(seed)\n","        all_results.append(seed_results)\n","        print(\"done\")\n","\n","    aggregated = aggregate_results(all_results)\n","\n","    # ========================================================================\n","    # PRINT COMPREHENSIVE RESULTS\n","    # ========================================================================\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"  AGGREGATED RESULTS ACROSS {} SEEDS\".format(CONFIG['n_seeds']))\n","    print(\"=\"*80)\n","\n","    treatments = ['untreated', 'ketamine', 'ssri', 'neurosteroid']\n","    labels = {\n","        'untreated': 'Untreated (pruned)',\n","        'ketamine': 'Ketamine-like',\n","        'ssri': 'SSRI-like',\n","        'neurosteroid': 'Neurosteroid-like'\n","    }\n","\n","    # ========================================================================\n","    # TABLE 1: EARLY ADVERSITY\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  TABLE 1: EARLY ADVERSITY (Uniform Random Scarring)\")\n","    print(\"-\"*80)\n","    ea = aggregated['early_adversity']\n","    print(f\"\\n  Initial scar fraction: {ea['mean']:.2f}% ± {ea['std']:.2f}% (range: {ea['min']:.2f}% - {ea['max']:.2f}%)\")\n","\n","    # ========================================================================\n","    # TABLE 2: ANTIDEPRESSANT EFFICACY\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  TABLE 2: ANTIDEPRESSANT EFFICACY (Mean ± Std)\")\n","    print(\"-\"*80)\n","    print(f\"\\n  {'Treatment':<22} {'Sparsity':>12} {'Scar %':>10} {'Clean':>14} {'Combined':>14}\")\n","    print(\"  \" + \"-\"*74)\n","\n","    for t in treatments:\n","        r = aggregated['treatments'][t]\n","        scar = r.get('scar_fraction', {'mean': 0, 'std': 0})\n","        print(f\"  {labels[t]:<22} \"\n","              f\"{r['sparsity']['mean']:>5.1f}±{r['sparsity']['std']:>4.1f}% \"\n","              f\"{scar['mean']:>4.1f}±{scar['std']:>3.1f}% \"\n","              f\"{r['clean']['mean']:>6.1f}±{r['clean']['std']:>4.1f}% \"\n","              f\"{r['combined']['mean']:>6.1f}±{r['combined']['std']:>4.1f}%\")\n","\n","    # ========================================================================\n","    # TABLE 3: MANIC CONVERSION RISK METRICS\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  TABLE 3: MANIC CONVERSION RISK METRICS (Mean ± Std)\")\n","    print(\"-\"*80)\n","    print(f\"\\n  {'Treatment':<22} {'Gain':>10} {'Biased Stress':>18} {'Act. Magnitude':>18}\")\n","    print(\"  \" + \"-\"*70)\n","\n","    for t in treatments:\n","        r = aggregated['treatments'][t]\n","        gain_str = f\"{r['gain']['mean']:>5.2f}±{r['gain']['std']:>4.2f}\"\n","        biased_str = f\"{r['biased_stress']['mean']:>6.1f}±{r['biased_stress']['std']:>4.1f}%\"\n","        act_str = f\"{r['activation_magnitude']['mean']:>6.3f}±{r['activation_magnitude']['std']:>5.3f}\"\n","        print(f\"  {labels[t]:<22} {gain_str:>10} {biased_str:>18} {act_str:>18}\")\n","\n","    # ========================================================================\n","    # TABLE 4: ACUTE RELAPSE VULNERABILITY\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  TABLE 4: ACUTE RELAPSE VULNERABILITY (Mean ± Std)\")\n","    print(\"-\"*80)\n","    print(f\"\\n  {'Treatment':<22} {'Relapse Drop':>18}\")\n","    print(\"  \" + \"-\"*42)\n","\n","    for t in ['ketamine', 'ssri', 'neurosteroid']:\n","        r = aggregated['treatments'][t]\n","        print(f\"  {labels[t]:<22} {r['relapse_drop']['mean']:>6.1f}±{r['relapse_drop']['std']:>4.1f}%\")\n","\n","    # ========================================================================\n","    # LONGITUDINAL MANIC RELAPSE RESULTS\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"  LONGITUDINAL MANIC RELAPSE AFTER DISCONTINUATION\")\n","    print(\"=\"*80)\n","\n","    print(\"\\n  Protocol: MS + antidepressant maintenance, then all medications discontinued.\")\n","    print(f\"            Manic relapse threshold: biased stress accuracy < {CONFIG['manic_relapse_threshold']:.0f}%\")\n","\n","    # ========================================================================\n","    # TABLE 5: OVERALL MANIC RELAPSE PROBABILITY\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  TABLE 5: OVERALL MANIC RELAPSE PROBABILITY\")\n","    print(\"-\"*80)\n","    print(f\"\\n  {'Treatment':<22} {'Mean':>10} {'Std':>10} {'Min':>10} {'Max':>10}\")\n","    print(\"  \" + \"-\"*64)\n","\n","    for t in ['ketamine', 'ssri', 'neurosteroid']:\n","        r = aggregated['longitudinal'][t]\n","        print(f\"  {labels[t]:<22} \"\n","              f\"{r['relapse_probability_mean']:>9.1f}% \"\n","              f\"{r['relapse_probability_std']:>9.1f}% \"\n","              f\"{r['relapse_probability_min']:>9.1f}% \"\n","              f\"{r['relapse_probability_max']:>9.1f}%\")\n","\n","    # ========================================================================\n","    # TABLE 6: MANIC RELAPSE BY MAINTENANCE DURATION\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  TABLE 6: MANIC RELAPSE RATE BY MAINTENANCE DURATION\")\n","    print(\"-\"*80)\n","\n","    durations = CONFIG['maintenance_durations']\n","    header = f\"  {'Treatment':<18}\"\n","    for dur in durations:\n","        header += f\" {dur:>8}\"\n","    print(f\"\\n{header} epochs\")\n","    print(\"  \" + \"-\"*(18 + 9*len(durations)))\n","\n","    for t in ['ketamine', 'ssri', 'neurosteroid']:\n","        row = f\"  {labels[t]:<18}\"\n","        for dur in durations:\n","            if dur in aggregated['longitudinal'][t]['per_duration']:\n","                rate = aggregated['longitudinal'][t]['per_duration'][dur]['relapse_rate']\n","                row += f\" {rate:>7.0f}%\"\n","            else:\n","                row += f\" {'N/A':>8}\"\n","        print(row)\n","\n","    # ========================================================================\n","    # KINDLING RESULTS\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"  KINDLING: PROGRESSIVE SENSITIZATION VIA REPEATED EPISODES\")\n","    print(\"=\"*80)\n","\n","    print(\"\\n  Architecture mechanism: Uniform base scarring upon each manic relapse.\")\n","    print(\"  Severity factor computed from current gain and activation magnitude (emergent).\")\n","    print(\"  Trigger bias weakens over cycles to test spontaneous episode emergence.\")\n","    print(f\"  Base scar sparsity: {CONFIG['kindling_base_scar_sparsity']*100:.1f}%\")\n","    print(f\"  Autonomy threshold: biased stress accuracy < {CONFIG['kindling_autonomy_threshold']:.0f}% at weak trigger\")\n","\n","    # ========================================================================\n","    # TABLE 7: KINDLING SUMMARY\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  TABLE 7: KINDLING SUMMARY (Mean ± Std)\")\n","    print(\"-\"*80)\n","    print(f\"\\n  {'Treatment':<18} {'Total Relapses':>16} {'Final Scar %':>14} {'Autonomy Rate':>14} {'Autonomy Acc':>14}\")\n","    print(\"  \" + \"-\"*78)\n","\n","    for t in ['ketamine', 'ssri', 'neurosteroid']:\n","        k = aggregated['kindling'][t]\n","        print(f\"  {labels[t]:<18} \"\n","              f\"{k['total_relapses_mean']:>7.1f}±{k['total_relapses_std']:>5.1f} \"\n","              f\"{k['final_scar_fraction_mean']:>6.1f}±{k['final_scar_fraction_std']:>4.1f}% \"\n","              f\"{k['autonomy_rate']:>13.0f}% \"\n","              f\"{k['autonomy_test_acc_mean']:>6.1f}±{k['autonomy_test_acc_std']:>4.1f}%\")\n","\n","    # ========================================================================\n","    # TABLE 8: KINDLING PROGRESSION BY CYCLE\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  TABLE 8: KINDLING PROGRESSION BY CYCLE\")\n","    print(\"-\"*80)\n","\n","    for t in ['ketamine', 'ssri', 'neurosteroid']:\n","        print(f\"\\n  {labels[t]}:\")\n","        print(f\"  {'Cycle':>6} {'Trigger':>8} {'Biased Acc':>14} {'Relapse %':>12} {'Scar %':>14} {'Severity':>10}\")\n","        print(\"  \" + \"-\"*66)\n","\n","        for cycle in range(CONFIG['kindling_num_cycles']):\n","            if cycle in aggregated['kindling'][t]['per_cycle']:\n","                c = aggregated['kindling'][t]['per_cycle'][cycle]\n","                print(f\"  {cycle:>6} {c['trigger_bias']:>8.2f} \"\n","                      f\"{c['biased_acc_mean']:>6.1f}±{c['biased_acc_std']:>4.1f}% \"\n","                      f\"{c['relapse_rate']:>11.0f}% \"\n","                      f\"{c['scar_fraction_mean']:>6.1f}±{c['scar_fraction_std']:>4.1f}% \"\n","                      f\"{c['severity_factor_mean']:>9.2f}\")\n","\n","    # ========================================================================\n","    # TABLE 9: KINDLING ARCHITECTURE PARAMETERS\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  TABLE 9: KINDLING ARCHITECTURE PARAMETERS\")\n","    print(\"-\"*80)\n","    print(f\"\\n  {'Parameter':<40} {'Value':>15}\")\n","    print(\"  \" + \"-\"*57)\n","    print(f\"  {'Base scar sparsity per episode':<40} {CONFIG['kindling_base_scar_sparsity']*100:>14.1f}%\")\n","    print(f\"  {'Severity factor range':<40} {CONFIG['kindling_severity_min']:>6.1f} - {CONFIG['kindling_severity_max']:.1f}\")\n","    print(f\"  {'Number of cycles':<40} {CONFIG['kindling_num_cycles']:>15}\")\n","    print(f\"  {'Initial trigger bias':<40} {CONFIG['kindling_initial_trigger_bias']:>15.2f}\")\n","    print(f\"  {'Final trigger bias':<40} {CONFIG['kindling_final_trigger_bias']:>15.2f}\")\n","    print(f\"  {'Autonomy test bias':<40} {0.3:>15.2f}\")\n","\n","    # ========================================================================\n","    # TABLE 10: NEUROSTEROID MEDICATION DEPENDENCE\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  TABLE 10: NEUROSTEROID MEDICATION DEPENDENCE (Mean ± Std)\")\n","    print(\"-\"*80)\n","\n","    neuro = aggregated['treatments']['neurosteroid']\n","    print(f\"\\n  {'Condition':<30} {'Combined':>18} {'Extreme':>18} {'Biased':>18}\")\n","    print(\"  \" + \"-\"*86)\n","    print(f\"  {'On medication':<30} \"\n","          f\"{neuro['combined']['mean']:>6.1f}±{neuro['combined']['std']:>4.1f}% \"\n","          f\"{neuro['stress_extreme']['mean']:>6.1f}±{neuro['stress_extreme']['std']:>4.1f}% \"\n","          f\"{neuro['biased_stress']['mean']:>6.1f}±{neuro['biased_stress']['std']:>4.1f}%\")\n","    print(f\"  {'Off medication':<30} \"\n","          f\"{neuro['off_medication_combined']['mean']:>6.1f}±{neuro['off_medication_combined']['std']:>4.1f}% \"\n","          f\"{neuro['off_medication_extreme']['mean']:>6.1f}±{neuro['off_medication_extreme']['std']:>4.1f}% \"\n","          f\"{neuro['off_medication_biased']['mean']:>6.1f}±{neuro['off_medication_biased']['std']:>4.1f}%\")\n","\n","    # ========================================================================\n","    # SUMMARY COMPARISON MATRIX\n","    # ========================================================================\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"  SUMMARY COMPARISON MATRIX\")\n","    print(\"=\"*80)\n","\n","    print(\"\"\"\n","  ┌─────────────────────┬────────────┬────────────┬──────────────┬─────────────┐\n","  │ Metric              │ Ketamine   │ SSRI       │ Neurosteroid │ Untreated   │\n","  ├─────────────────────┼────────────┼────────────┼──────────────┼─────────────┤\"\"\")\n","\n","    ket = aggregated['treatments']['ketamine']\n","    ssri = aggregated['treatments']['ssri']\n","    neuro = aggregated['treatments']['neurosteroid']\n","    untreated = aggregated['treatments']['untreated']\n","\n","    print(f\"  │ Combined Stress (%) │ {ket['combined']['mean']:>10.1f} │ {ssri['combined']['mean']:>10.1f} │ {neuro['combined']['mean']:>12.1f} │ {untreated['combined']['mean']:>11.1f} │\")\n","    print(f\"  │ Biased Stress (%)   │ {ket['biased_stress']['mean']:>10.1f} │ {ssri['biased_stress']['mean']:>10.1f} │ {neuro['biased_stress']['mean']:>12.1f} │ {untreated['biased_stress']['mean']:>11.1f} │\")\n","    print(f\"  │ Gain Multiplier     │ {ket['gain']['mean']:>10.2f} │ {ssri['gain']['mean']:>10.2f} │ {neuro['gain']['mean']:>12.2f} │ {untreated['gain']['mean']:>11.2f} │\")\n","    print(f\"  │ Acute Relapse Drop  │ {ket['relapse_drop']['mean']:>10.1f} │ {ssri['relapse_drop']['mean']:>10.1f} │ {neuro['relapse_drop']['mean']:>12.1f} │         N/A │\")\n","\n","    ket_long = aggregated['longitudinal']['ketamine']\n","    ssri_long = aggregated['longitudinal']['ssri']\n","    neuro_long = aggregated['longitudinal']['neurosteroid']\n","\n","    print(f\"  │ Long. Relapse Prob. │ {ket_long['relapse_probability_mean']:>9.1f}% │ {ssri_long['relapse_probability_mean']:>9.1f}% │ {neuro_long['relapse_probability_mean']:>11.1f}% │         N/A │\")\n","\n","    ket_kind = aggregated['kindling']['ketamine']\n","    ssri_kind = aggregated['kindling']['ssri']\n","    neuro_kind = aggregated['kindling']['neurosteroid']\n","\n","    print(f\"  │ Kindling Relapses   │ {ket_kind['total_relapses_mean']:>10.1f} │ {ssri_kind['total_relapses_mean']:>10.1f} │ {neuro_kind['total_relapses_mean']:>12.1f} │         N/A │\")\n","    print(f\"  │ Final Scar (%)      │ {ket_kind['final_scar_fraction_mean']:>10.1f} │ {ssri_kind['final_scar_fraction_mean']:>10.1f} │ {neuro_kind['final_scar_fraction_mean']:>12.1f} │         N/A │\")\n","    print(f\"  │ Autonomy Rate (%)   │ {ket_kind['autonomy_rate']:>10.0f} │ {ssri_kind['autonomy_rate']:>10.0f} │ {neuro_kind['autonomy_rate']:>12.0f} │         N/A │\")\n","\n","    print(\"  └─────────────────────┴────────────┴────────────┴──────────────┴─────────────┘\")\n","\n","    # ========================================================================\n","    # KINDLING RISK RANKING\n","    # ========================================================================\n","    print(\"\\n\" + \"-\"*80)\n","    print(\"  KINDLING RISK RANKING (by autonomy rate and total relapses)\")\n","    print(\"-\"*80)\n","\n","    risk_data = [\n","        ('Ketamine-like', ket_kind['autonomy_rate'], ket_kind['total_relapses_mean'], ket_kind['final_scar_fraction_mean']),\n","        ('SSRI-like', ssri_kind['autonomy_rate'], ssri_kind['total_relapses_mean'], ssri_kind['final_scar_fraction_mean']),\n","        ('Neurosteroid-like', neuro_kind['autonomy_rate'], neuro_kind['total_relapses_mean'], neuro_kind['final_scar_fraction_mean'])\n","    ]\n","    risk_data.sort(key=lambda x: (x[1], x[2]))\n","\n","    print(f\"\\n  {'Rank':<6} {'Treatment':<22} {'Autonomy %':>12} {'Relapses':>12} {'Final Scar %':>14}\")\n","    print(\"  \" + \"-\"*68)\n","\n","    for i, (name, auto, rel, scar) in enumerate(risk_data):\n","        print(f\"  {i+1:<6} {name:<22} {auto:>11.0f}% {rel:>12.1f} {scar:>13.1f}%\")\n","\n","    print(\"\\n  Note: Lower autonomy rate and fewer relapses = better kindling resistance\")\n","    print(\"        Scar accumulation reflects permanent structural damage from episodes\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"  EXPERIMENT COMPLETE\")\n","    print(\"  GRU-based recurrent architecture with per-step modulations\")\n","    print(\"  Results averaged across {} random seeds\".format(CONFIG['n_seeds']))\n","    print(\"=\"*80 + \"\\n\")\n","\n","    return {'all_results': all_results, 'aggregated': aggregated}\n","\n","\n","# ============================================================================\n","# ENTRY POINT\n","# ============================================================================\n","if __name__ == \"__main__\":\n","    print(\"\\n\" + \"#\"*80)\n","    print(\"#\" + \" \"*78 + \"#\")\n","    print(\"#\" + \" MULTI-MECHANISM ANTIDEPRESSANT COMPARISON \".center(78) + \"#\")\n","    print(\"#\" + \" WITH MANIC CONVERSION + LONGITUDINAL RELAPSE + KINDLING \".center(78) + \"#\")\n","    print(\"#\" + \" GRU-BASED RECURRENT ARCHITECTURE \".center(78) + \"#\")\n","    print(\"#\" + \" Ketamine vs SSRI vs Neurosteroid \".center(78) + \"#\")\n","    print(\"#\" + f\" ({CONFIG['n_seeds']} Random Seeds) \".center(78) + \"#\")\n","    print(\"#\" + \" \"*78 + \"#\")\n","    print(\"#\"*80)\n","\n","    results = run_multi_seed_experiment()"]},{"cell_type":"markdown","source":["# The End"],"metadata":{"id":"vaPikYfRC4Rc"}}]}